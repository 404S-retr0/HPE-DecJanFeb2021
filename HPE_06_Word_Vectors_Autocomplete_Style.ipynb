{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPE 06- Word Vectors Autocomplete Style.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1I0uo6ojO0dq2BcVUkQiZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QMNJrZPqCD-",
        "outputId": "64b67694-a057-47d7-d8a5-fed60e999caa"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpB4AJIaqF1t",
        "outputId": "f2940256-25c0-4fff-ca6b-044a43a90b27"
      },
      "source": [
        "# DICTIONARY method for NLP inputs \n",
        "sent = 'Shaktiman is red in color. Pikachu is yellow in color. He is not a rich duck.'\n",
        "corpus_lower = sent.lower()\n",
        "words = []\n",
        "for word in corpus_lower.split():\n",
        "  if word != '.':\n",
        "    word = word.replace('.','')\n",
        "    words.append(word)\n",
        "\n",
        "words\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['shaktiman',\n",
              " 'is',\n",
              " 'red',\n",
              " 'in',\n",
              " 'color',\n",
              " 'pikachu',\n",
              " 'is',\n",
              " 'yellow',\n",
              " 'in',\n",
              " 'color',\n",
              " 'he',\n",
              " 'is',\n",
              " 'not',\n",
              " 'a',\n",
              " 'rich',\n",
              " 'duck']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB-zN-w8rfHw",
        "outputId": "6e5b4715-77c1-4c34-9476-53958ae1c9bc"
      },
      "source": [
        "unique_words = set(words)\n",
        "unique_words"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'color',\n",
              " 'duck',\n",
              " 'he',\n",
              " 'in',\n",
              " 'is',\n",
              " 'not',\n",
              " 'pikachu',\n",
              " 'red',\n",
              " 'rich',\n",
              " 'shaktiman',\n",
              " 'yellow'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-IfoRefrpOr",
        "outputId": "f420b397-1f1c-440f-a737-7e19635dbbc3"
      },
      "source": [
        "word2int = {}\n",
        "int2word = {}\n",
        "vocab_size = len(unique_words)\n",
        "for i,word in enumerate(unique_words):\n",
        "  word2int[word] = i\n",
        "  int2word[i] = word \n",
        "print(word2int)\n",
        "print(int2word)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'rich': 0, 'a': 1, 'color': 2, 'red': 3, 'pikachu': 4, 'is': 5, 'in': 6, 'not': 7, 'he': 8, 'duck': 9, 'shaktiman': 10, 'yellow': 11}\n",
            "{0: 'rich', 1: 'a', 2: 'color', 3: 'red', 4: 'pikachu', 5: 'is', 6: 'in', 7: 'not', 8: 'he', 9: 'duck', 10: 'shaktiman', 11: 'yellow'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouxXt2ANtFXf",
        "outputId": "3b1dd160-18d4-443f-8f04-788cd158ccc9"
      },
      "source": [
        "raw_sentences = sent.split('.')\n",
        "sentences = []\n",
        "for sentence in raw_sentences:\n",
        "  sentences.append(sentence.split())\n",
        "\n",
        "print(sentences)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Shaktiman', 'is', 'red', 'in', 'color'], ['Pikachu', 'is', 'yellow', 'in', 'color'], ['He', 'is', 'not', 'a', 'rich', 'duck'], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "296c3-wStGE0",
        "outputId": "54de6d4b-4498-4a06-c6fb-95959afdfa63"
      },
      "source": [
        "sentences = sentences[:-1]\n",
        "sentences"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Shaktiman', 'is', 'red', 'in', 'color'],\n",
              " ['Pikachu', 'is', 'yellow', 'in', 'color'],\n",
              " ['He', 'is', 'not', 'a', 'rich', 'duck']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej-IeuPDt9VC",
        "outputId": "55865544-bd4a-4257-ec0e-62b0434d41eb"
      },
      "source": [
        "# Autocomplete \n",
        "# [INPUT]-> 1 output word \n",
        "\n",
        "# ML Algo-> y = mx + c\n",
        "# y => next word\n",
        "# y = weights * inputs + bias \n",
        "# weights = 1-D filters\n",
        "# inputs-> words provided\n",
        "\n",
        "# next_word = weights * previous_word + bias \n",
        "# ALL POSSIBLE COMBINATIONS of WORD PAIRS \n",
        "\n",
        "# filter_pairs -> [prev, next]\n",
        "window_size = 2\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "  for wordId,word in enumerate(sentence):\n",
        "    for nxword in sentence[max(wordId - window_size,0):min(wordId + window_size, len(sentence))+1]:\n",
        "      if nxword != word:\n",
        "        data.append([word,nxword])\n",
        "\n",
        "data\n",
        "#LIMIT for all possible combination \n",
        "# from min to max possible lengths \n",
        "# "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Shaktiman', 'is'],\n",
              " ['Shaktiman', 'red'],\n",
              " ['is', 'Shaktiman'],\n",
              " ['is', 'red'],\n",
              " ['is', 'in'],\n",
              " ['red', 'Shaktiman'],\n",
              " ['red', 'is'],\n",
              " ['red', 'in'],\n",
              " ['red', 'color'],\n",
              " ['in', 'is'],\n",
              " ['in', 'red'],\n",
              " ['in', 'color'],\n",
              " ['color', 'red'],\n",
              " ['color', 'in'],\n",
              " ['Pikachu', 'is'],\n",
              " ['Pikachu', 'yellow'],\n",
              " ['is', 'Pikachu'],\n",
              " ['is', 'yellow'],\n",
              " ['is', 'in'],\n",
              " ['yellow', 'Pikachu'],\n",
              " ['yellow', 'is'],\n",
              " ['yellow', 'in'],\n",
              " ['yellow', 'color'],\n",
              " ['in', 'is'],\n",
              " ['in', 'yellow'],\n",
              " ['in', 'color'],\n",
              " ['color', 'yellow'],\n",
              " ['color', 'in'],\n",
              " ['He', 'is'],\n",
              " ['He', 'not'],\n",
              " ['is', 'He'],\n",
              " ['is', 'not'],\n",
              " ['is', 'a'],\n",
              " ['not', 'He'],\n",
              " ['not', 'is'],\n",
              " ['not', 'a'],\n",
              " ['not', 'rich'],\n",
              " ['a', 'is'],\n",
              " ['a', 'not'],\n",
              " ['a', 'rich'],\n",
              " ['a', 'duck'],\n",
              " ['rich', 'not'],\n",
              " ['rich', 'a'],\n",
              " ['rich', 'duck'],\n",
              " ['duck', 'a'],\n",
              " ['duck', 'rich']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aocrxMeOy-eh",
        "outputId": "88052539-369d-4a1c-ebdd-d34aee6830c4"
      },
      "source": [
        "window_size = 1\n",
        "data_single = []\n",
        "for sentence in sentences:\n",
        "  for wordId,word in enumerate(sentence):\n",
        "    for nxword in sentence[max(wordId - window_size,0):min(wordId + window_size, len(sentence))+1]:\n",
        "      if nxword != word:\n",
        "        data_single.append([word,nxword])\n",
        "\n",
        "data_single"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Shaktiman', 'is'],\n",
              " ['is', 'Shaktiman'],\n",
              " ['is', 'red'],\n",
              " ['red', 'is'],\n",
              " ['red', 'in'],\n",
              " ['in', 'red'],\n",
              " ['in', 'color'],\n",
              " ['color', 'in'],\n",
              " ['Pikachu', 'is'],\n",
              " ['is', 'Pikachu'],\n",
              " ['is', 'yellow'],\n",
              " ['yellow', 'is'],\n",
              " ['yellow', 'in'],\n",
              " ['in', 'yellow'],\n",
              " ['in', 'color'],\n",
              " ['color', 'in'],\n",
              " ['He', 'is'],\n",
              " ['is', 'He'],\n",
              " ['is', 'not'],\n",
              " ['not', 'is'],\n",
              " ['not', 'a'],\n",
              " ['a', 'not'],\n",
              " ['a', 'rich'],\n",
              " ['rich', 'a'],\n",
              " ['rich', 'duck'],\n",
              " ['duck', 'rich']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9yB4zGyzMoP"
      },
      "source": [
        "# ENCODING techniques\n",
        "# SENTIMENT analysis-> label encoding \n",
        "# [hello, worlds,..]-> [0,1...]\n",
        "\n",
        "# One-Hot Encoding\n",
        "# Sales City Profit     ->.   Sales.  CITY_BLR.   CITY_MAA. CITY_NDLS Profit\n",
        "#. 1.    BLR.  100                       1         0         0\n",
        "#. 2.    MAA.  200                       0         1          0\n",
        "#. 3.    MAA.  100                       0         1         0\n",
        "#. 4.    NDLS.   10.                     0          0        1\n",
        "#. 5.    BLR.   50\n",
        "#. 6.    MAA.   20\n",
        "\n",
        "# Profit = w1*sales + w2*city_blr + w3*city_maa + bias \n",
        "# for MAA specific, BLR = 0, for BLR specific, MAA=0\n",
        "# for MAA, blr*w2 =0 , for BLR, maa*w3 = 0\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Kq111T2hDj"
      },
      "source": [
        "# ONE HOT ENCODING for my dictionary\n",
        "# EVERY WORD in my dictionary should be 1 hot encoded!!!\n",
        "\n",
        "def Encoder(datapointindex, vocab_size):\n",
        "  temp = np.zeros(vocab_size)\n",
        "  temp[datapointindex] = 1\n",
        "  return temp\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egVNvifB3iP0"
      },
      "source": [
        "trainx = []\n",
        "trainy = []\n",
        "for worddata in data:\n",
        "  try:\n",
        "    trainx.append(Encoder(word2int[worddata[0]], vocab_size))\n",
        "    trainy.append(Encoder(word2int[worddata[1]], vocab_size))\n",
        "  except:\n",
        "    continue\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLru9dmK4Xci",
        "outputId": "cc2907b5-1682-4fd8-8e03-4902c3bf55db"
      },
      "source": [
        "trainy"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kICTphED4YfC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}